---
标题: 理解 pgvector 的关键向量数据库概念：  
摘录: 用于理解 PostgreSQL 中人工智能的最重要的向量数据库概念 pgvector、pgvectorscale 以及 pgai   
产品: [云]  
关键字: [ai, 向量, pgvector, pgvectorscale, pgai]  
标签: [ai, 向量]
---

<!-- vale Google.Headings = NO -->
# 理解 pgvector 的关键向量数据库概念

<!-- vale Google.Headings = YES -->
## `Vector`由 pgvector 提供的数据类型

数据库中的向量使用`vector` 列存储在常规的PostgreSQL表中。该`vector`列类型是由 pgvector 扩展提供的一种常见的存储向量的方法是将它们与已索引的数据一起存储。例如，要存储文档的嵌入向量，常见的表结构如下：

```sql
CREATE TABLE IF NOT EXISTS document_embedding  (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    document_id BIGINT FOREIGN KEY(document.id)
    metadata JSONB,
    contents TEXT,
    embedding VECTOR(1536)
)
```

这个表包含一个主键、一个指向文档表的外键、一些元数据、被嵌入的文本（在 contents`contents` 列中），以及嵌入向量

这可能看起来有点奇怪：为什么嵌入向量不只是文档表中的一个单独列呢？答案与嵌入模型和语言模型（LLMs）的上下文长度限制有关。在嵌入数据时，你可以嵌入的内容长度是有限制的（例如，OpenAI 的 ada - 002 有 8191 个令牌的限制），因此，如果你要嵌入一大段文本，你必须将其分解成更小的块，并分别嵌入每个块。因此，在数据库层考虑这个问题时，通常在被嵌入的事物和嵌入向量之间存在一对多的关系，这种关系通过从嵌入到被嵌入事物的外键来表示。

当然，如果你不想在数据库中存储原始数据，而只存储嵌入向量，那也完全没问题。只需从表中省略外键。另一个流行的替代方法是将外键放入元数据 JSONB 中。

## 使用 pgvector 查询向量

对向量的标准查询是查询与用户查询的嵌入向量最接近的向量。这也被称为寻找 [K 近邻](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)。

在下面的示例查询中，`$1` 是一个接受查询嵌入向量的参数，而 `<=>` 操作符计算查询嵌入向量和存储在数据库中的嵌入向量之间的距离（并返回一个浮点值）。

```sql
SELECT *
FROM document_embedding
ORDER BY embedding <=> $1
LIMIT 10
```

上述查询返回与查询的嵌入向量距离最小的 10 行。当然，由于这是 PostgreSQL，你可以添加额外的 `WHERE` 子句（例如对元数据的筛选）、连接等。

### 向量距离类型

上面展示的查询使用了所谓的余弦距离（使用 \<=> 操作符）作为衡量两个嵌入向量相似程度的方法。但是，有多种方法来量化两个向量彼此之间的距离。

<Highlight type="note">
在实际应用中，距离度量方式的选择影响不大，对于大多数应用场景，建议坚持使用余弦距离即可。
</Highlight>

#### 余弦距离、负内积和欧几里得距离的描述

这是对三种常见向量距离度量的简要描述。

- **余弦距离（又名角度距离）**：这种方法衡量两个向量之间的角度。它在数学意义上并非真正的 “距离”，而是一种相似性度量，其中较小的角度对应较高的相似性。余弦距离在高维空间中特别有用，在这些空间中向量的大小（它们的长度）不太重要，例如在文本分析或信息检索中。它的取值范围从 - 1（意味着完全相反）到 1（完全相同），0 通常表示正交（无相似性）。查看这里获取更多关于[余弦相似度](https://en.wikipedia.org/wiki/Cosine_similarity)的信息。

- **负内积**：这仅仅是两个向量内积（也称为点积）的负值。内积根据向量的大小和它们之间角度的余弦来衡量向量的相似性。较高的内积表明更大的相似性。然而，需要注意的是，与余弦相似度不同，向量的大小会影响内积。

- **欧几里得距离**：这是欧几里得空间中两点之间的 “普通” 直线距离。就向量而言，它是向量对应元素间平方差之和的平方根。这种度量对向量的大小很敏感，广泛用于聚类和最近邻搜索等各个领域。

许多嵌入系统（例如 OpenAI 的 ada - 002）使用长度为 1 的向量（单位向量）。对于那些系统，所有度量的排名（顺序）都是相同的。特别是，

- 余弦距离是 `1−dot product`。
- 负内积是`−dot product`
- 欧几里得距离与点积有关，其中欧几里得距离是`2(1−dot product)`

<!-- vale Google.Headings = NO -->
#### 在 PostgreSQL 中推荐使用的向量距离

<!-- vale Google.Headings = YES -->
推荐使用余弦距离，特别是在单位向量上。这些推荐是基于 OpenAI 的[推荐](https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use)，以及在单位向量上不同距离的排名得以保留这一事实。

## 向量搜索索引（近似最近邻搜索）

在 PostgreSQL 和其他关系型数据库中，索引是一种加速（查询）的方法。对于向量数据，索引可加速上述所示的相似性搜索查询，即找到与给定查询嵌入最相似的嵌入。这个问题通常被称为寻找 [K 近邻](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)。

<Highlight type="note">
在向量数据库的语境中，“索引” 一词有多种含义。它既可以指代数据的存储机制，也可以指代提高查询效率的工具。这些文档采用的是后一种含义。
</Highlight>
在 PostgreSQL 中寻找 K 近邻不是一个新问题，但现有的技术仅适用于低维数据。当处理大于约 10 维的数据时，这些方法由于 “维度灾难” 而失效。鉴于嵌入通常具有超过一千维（OpenAI 的有 1,536 维），因此必须开发新技术。

对于在这种高维空间中进行高效搜索，不存在精确的算法。然而，有一些优秀的近似算法属于近似最近邻算法范畴。

<!-- vale Google.Colons = NO -->
在 Timescale 的 pgvector 上有 3 种不同的索引算法可用：StreamingDiskANN、HNSW 和 ivflat。下表说明了这些算法之间的高层次差异：

<!-- vale Google.Colons = YES -->
| 算法| 构建速度| 查询速度| 更新后是否需要重建|
|----------|----------|----------|----------|
| StreamingDiskANN| 快| 最快| 否|
| HNSW| 快| 快| 否|
| ivfflat| 最快| 最慢| 是|

查看性能基准[performance benchmarks](https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/)以获取关于每个索引在 100 万个 OpenAI 嵌入数据集上表现的详细信息。

## 推荐的索引类型

对于大多数应用程序，推荐使用 StreamingDiskANN 索引。
